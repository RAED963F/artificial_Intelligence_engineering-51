from __future__ import annotations

from pathlib import Path
from typing import Optional

import pandas as pd
import typer

from .core import (
    DatasetSummary,
    compute_quality_flags,
    correlation_matrix,
    flatten_summary_for_print,
    missing_table,
    summarize_dataset,
    top_categories,
)
from .viz import (
    plot_correlation_heatmap,
    plot_missing_matrix,
    plot_histograms_per_column,
    save_top_categories_tables,
)

app = typer.Typer(help="–ú–∏–Ω–∏-CLI –¥–ª—è EDA CSV-—Ñ–∞–π–ª–æ–≤")


def _load_csv(
    path: Path,
    sep: str = ",",
    encoding: str = "utf-8",
) -> pd.DataFrame:
    if not path.exists():
        raise typer.BadParameter(f"–§–∞–π–ª '{path}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
    try:
        return pd.read_csv(path, sep=sep, encoding=encoding)
    except Exception as exc:  # noqa: BLE001
        raise typer.BadParameter(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV: {exc}") from exc


@app.command()
def overview(
    path: str = typer.Argument(..., help="–ü—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É."),
    sep: str = typer.Option(",", help="–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –≤ CSV."),
    encoding: str = typer.Option("utf-8", help="–ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞."),
) -> None:
    """
    –ù–∞–ø–µ—á–∞—Ç–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:
    - —Ä–∞–∑–º–µ—Ä—ã;
    - —Ç–∏–ø—ã;
    - –ø—Ä–æ—Å—Ç–∞—è —Ç–∞–±–ª–∏—á–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º.
    """
    df = _load_csv(Path(path), sep=sep, encoding=encoding)
    summary: DatasetSummary = summarize_dataset(df)
    summary_df = flatten_summary_for_print(summary)

    typer.echo(f"–°—Ç—Ä–æ–∫: {summary.n_rows}")
    typer.echo(f"–°—Ç–æ–ª–±—Ü–æ–≤: {summary.n_cols}")
    typer.echo("\n–ö–æ–ª–æ–Ω–∫–∏:")
    typer.echo(summary_df.to_string(index=False))

@app.command()
def report(
    path: str = typer.Argument(..., help="–ü—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É."),
    out_dir: str = typer.Option("reports", help="–ö–∞—Ç–∞–ª–æ–≥ –¥–ª—è –æ—Ç—á—ë—Ç–∞."),
    sep: str = typer.Option(",", help="–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –≤ CSV."),
    encoding: str = typer.Option("utf-8", help="–ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞."),
    max_hist_columns: int = typer.Option(6, help="–ú–∞–∫—Å–∏–º—É–º —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º."),
    
    # ‚≠ê‚≠ê‚≠ê –ù–û–í–´–ï –ü–ê–†–ê–ú–ï–¢–†–´:
    # 1. –ü–æ—Ä–æ–≥ –¥–ª—è –≤—ã—Å–æ–∫–æ–π –¥–æ–ª–∏ –Ω—É–ª–µ–π
    zero_threshold: float = typer.Option(
        30.0, 
        help="–ü–æ—Ä–æ–≥ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –Ω—É–ª–µ–π –¥–ª—è –ø–æ–º–µ—Ç–∫–∏ —Å—Ç–æ–ª–±—Ü–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30%)."
    ),
    
    # 2. –í–∫–ª—é—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    advanced_quality_check: bool = typer.Option(
        False,
        help="–í–∫–ª—é—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö (–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –≤—ã–±—Ä–æ—Å—ã –∏ —Ç.–¥.)."
    ),
    
    # 3. –ü–æ—Ä–æ–≥ –¥–ª—è –≤—ã–±—Ä–æ—Å–æ–≤ (IQR –º–Ω–æ–∂–∏—Ç–µ–ª—å)
    iqr_multiplier: float = typer.Option(
        1.5,
        help="–ú–Ω–æ–∂–∏—Ç–µ–ª—å IQR –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.5)."
    ),
    
    # 4. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞
    min_missing_for_detail: float = typer.Option(
        5.0,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø–æ —Å—Ç–æ–ª–±—Ü—É."
    ),
    
    # 5. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    top_k_categories: int = typer.Option(
        10,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
    ),
    
    # 6. –í–∫–ª—é—á–µ–Ω–∏–µ/–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
    include_correlation: bool = typer.Option(
        True,
        help="–í–∫–ª—é—á–∞—Ç—å –ª–∏ –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –≤ –æ—Ç—á—ë—Ç."
    ),
) -> None:
    """
    –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π EDA-–æ—Ç—á—ë—Ç —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏.
    –í–∫–ª—é—á–∞–µ—Ç –Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞.
    """
    # –¢–∞–π–º–µ—Ä –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    import time
    start_time = time.time()
    
    out_root = Path(out_dir)
    out_root.mkdir(parents=True, exist_ok=True)
    
    # –°–æ–∑–¥–∞—ë–º –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–∏
    figures_dir = out_root / "figures"
    figures_dir.mkdir(exist_ok=True)
    
    typer.echo("=" * 60)
    typer.echo("üìä –ó–ê–ü–£–°–ö –†–ê–°–®–ò–†–ï–ù–ù–û–ì–û EDA-–ê–ù–ê–õ–ò–ó–ê")
    typer.echo("=" * 60)
    typer.echo(f"üìÅ –§–∞–π–ª: {path}")
    typer.echo(f"üìÇ –í—ã—Ö–æ–¥–Ω–æ–π –∫–∞—Ç–∞–ª–æ–≥: {out_dir}")
    
    if advanced_quality_check:
        typer.echo("üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞: –í–ö–õ–Æ–ß–ï–ù")
        typer.echo(f"‚öôÔ∏è  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: zero_threshold={zero_threshold}%, iqr_multiplier={iqr_multiplier}")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    typer.echo("\n‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    try:
        df = _load_csv(Path(path), sep=sep, encoding=encoding)
        typer.echo(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    except Exception as e:
        typer.echo(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}", err=True)
        raise typer.Exit(1)
    
    # 2. –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
    typer.echo("‚è≥ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
    summary = summarize_dataset(df)
    summary_df = flatten_summary_for_print(summary)
    missing_df = missing_table(df)
    
    # 3. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    corr_df = pd.DataFrame()
    if include_correlation:
        typer.echo("‚è≥ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã...")
        corr_df = correlation_matrix(df)
    
    # 4. –¢–æ–ø-–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –Ω–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º top_k_categories
    typer.echo(f"‚è≥ –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (top-{top_k_categories})...")
    top_cats = top_categories(df, top_k=top_k_categories)
    
    # 5. –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
    if advanced_quality_check:
        typer.echo("‚è≥ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö...")
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è compute_quality_flags
        quality_flags = compute_quality_flags_extended(
            summary=summary,
            missing_df=missing_df,
            df=df,
            zero_threshold=zero_threshold,
            iqr_multiplier=iqr_multiplier,
            verbose=True
        )
    else:
        quality_flags = compute_quality_flags(summary, missing_df)
    
    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    typer.echo("‚è≥ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    # 6.1. –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    summary_df.to_csv(out_root / "summary.csv", index=False)
    
    # 6.2. –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    if not missing_df.empty:
        missing_df.to_csv(out_root / "missing.csv", index=True)
    
    # 6.3. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    if include_correlation and not corr_df.empty:
        corr_df.to_csv(out_root / "correlation.csv", index=True)
    
    # 6.4. –¢–æ–ø-–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    if top_cats:
        save_top_categories_tables(top_cats, out_root / "top_categories")
    
    # 6.5. –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if advanced_quality_check:
        quality_flags_path = out_root / "quality_flags.json"
        import json
        with open(quality_flags_path, 'w', encoding='utf-8') as f:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy —Ç–∏–ø—ã –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            def convert_for_json(obj):
                if isinstance(obj, (np.integer, np.floating)):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, pd.Timestamp):
                    return obj.isoformat()
                return obj
            
            serializable_flags = {}
            for key, value in quality_flags.items():
                if isinstance(value, (list, dict)):
                    serializable_flags[key] = json.loads(
                        json.dumps(value, default=convert_for_json)
                    )
                else:
                    serializable_flags[key] = convert_for_json(value)
            
            json.dump(serializable_flags, f, indent=2, ensure_ascii=False)
    
    # 7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown-–æ—Ç—á—ë—Ç–∞
    typer.echo("‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown-–æ—Ç—á—ë—Ç–∞...")
    md_path = out_root / "report.md"
    
    with md_path.open("w", encoding="utf-8") as f:
        # ==================== –ó–ê–ì–û–õ–û–í–û–ö ====================
        f.write(f"# üìä EDA-–æ—Ç—á—ë—Ç: –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö\n\n")
        f.write(f"**–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª:** `{Path(path).name}`\n")
        f.write(f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** {time.time() - start_time:.2f} —Å–µ–∫—É–Ω–¥\n\n")
        
        # ==================== –ü–ê–†–ê–ú–ï–¢–†–´ –ê–ù–ê–õ–ò–ó–ê ====================
        f.write("## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞\n\n")
        f.write("| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
        f.write("|----------|----------|\n")
        f.write(f"| –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV | `{sep}` |\n")
        f.write(f"| –ö–æ–¥–∏—Ä–æ–≤–∫–∞ | `{encoding}` |\n")
        f.write(f"| –ú–∞–∫—Å. –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º | `{max_hist_columns}` |\n")
        f.write(f"| –¢–æ–ø-K –∫–∞—Ç–µ–≥–æ—Ä–∏–π | `{top_k_categories}` |\n")
        f.write(f"| –í–∫–ª. –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é | `{include_correlation}` |\n")
        
        if advanced_quality_check:
            f.write(f"| –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ | **–í–∫–ª—é—á—ë–Ω** |\n")
            f.write(f"| –ü–æ—Ä–æ–≥ –Ω—É–ª–µ–π | `{zero_threshold}%` |\n")
            f.write(f"| –ú–Ω–æ–∂–∏—Ç–µ–ª—å IQR | `{iqr_multiplier}` |\n")
            f.write(f"| –ü–æ—Ä–æ–≥ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤ | `{min_missing_for_detail}%` |\n")
        else:
            f.write(f"| –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ | –í—ã–∫–ª—é—á–µ–Ω |\n")
        
        f.write("\n")
        
        # ==================== –û–°–ù–û–í–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò ====================
        f.write("## üìà –û—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n\n")
        f.write(f"- **–°—Ç—Ä–æ–∫ (–∑–∞–ø–∏—Å–µ–π):** `{summary.n_rows}`\n")
        f.write(f"- **–°—Ç–æ–ª–±—Ü–æ–≤ (–ø—Ä–∏–∑–Ω–∞–∫–æ–≤):** `{summary.n_cols}`\n")
        f.write(f"- **–ß–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤:** `{summary.n_numeric}`\n")
        f.write(f"- **–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤:** `{summary.n_categorical}`\n")
        f.write(f"- **–°—Ç–æ–ª–±—Ü–æ–≤ —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º:** `{summary.n_datetime}`\n")
        f.write(f"- **–î—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤:** `{summary.n_other}`\n\n")
        
        # ==================== –ö–ê–ß–ï–°–¢–í–û –î–ê–ù–ù–´–• ====================
        f.write("## üîç –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö\n\n")
        
        # –û–±—â–∏–π score
        f.write(f"### –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n")
        f.write(f"**Score:** `{quality_flags.get('quality_score', 0):.2f}` –∏–∑ 1.0\n\n")
        
        # –ë–∞–∑–æ–≤—ã–µ —Ñ–ª–∞–≥–∏
        f.write(f"### –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏\n")
        f.write(f"- –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Å—Ç—Ä–æ–∫ (<100): **{quality_flags['too_few_rows']}**\n")
        f.write(f"- –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–æ–≤ (>100): **{quality_flags['too_many_columns']}**\n")
        f.write(f"- –ú–∞–∫—Å. –¥–æ–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤: **{quality_flags['max_missing_share']:.2%}**\n")
        f.write(f"- –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ (>50%): **{quality_flags['too_many_missing']}**\n\n")
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã)
        if advanced_quality_check:
            f.write(f"### –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏\n")
            
            # –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            if quality_flags.get('has_constant_columns', False):
                f.write(f"- ‚ö†Ô∏è **–ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:** –î–ê ({quality_flags.get('n_constant_columns', 0)} —à—Ç.)\n")
                if quality_flags.get('constant_columns'):
                    f.write("  –°—Ç–æ–ª–±—Ü—ã:\n")
                    for col_info in quality_flags['constant_columns'][:5]:  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                        f.write(f"  - `{col_info['column']}` = `{col_info['value']}`\n")
                    if len(quality_flags['constant_columns']) > 5:
                        f.write(f"  ... –∏ –µ—â—ë {len(quality_flags['constant_columns']) - 5} —Å—Ç–æ–ª–±—Ü–æ–≤\n")
            else:
                f.write(f"- ‚úÖ **–ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:** –ù–µ—Ç\n")
            
            # –í—ã–±—Ä–æ—Å—ã
            if quality_flags.get('has_outliers', False):
                f.write(f"- ‚ö†Ô∏è **–í—ã–±—Ä–æ—Å—ã –≤ –¥–∞–Ω–Ω—ã—Ö:** –î–ê ({quality_flags.get('n_outlier_columns', 0)} —Å—Ç–æ–ª–±—Ü–æ–≤)\n")
                if quality_flags.get('outlier_columns'):
                    f.write("  –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:\n")
                    for col_info in quality_flags['outlier_columns'][:3]:  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                        f.write(f"  - `{col_info['column']}`: {col_info['n_outliers']} –≤—ã–±—Ä–æ—Å–æ–≤ ({col_info['outlier_percentage']}%)\n")
            else:
                f.write(f"- ‚úÖ **–í—ã–±—Ä–æ—Å—ã –≤ –¥–∞–Ω–Ω—ã—Ö:** –ù–µ—Ç\n")
            
            # –î—É–±–ª–∏–∫–∞—Ç—ã ID
            if quality_flags.get('has_id_duplicates', False):
                f.write(f"- ‚ö†Ô∏è **–î—É–±–ª–∏–∫–∞—Ç—ã ID:** –î–ê\n")
                if quality_flags.get('id_duplicate_issues'):
                    for issue in quality_flags['id_duplicate_issues'][:2]:
                        f.write(f"  - `{issue['column']}`: {issue['n_duplicates']} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ({issue['duplicate_percentage']}%)\n")
            else:
                f.write(f"- ‚úÖ **–î—É–±–ª–∏–∫–∞—Ç—ã ID:** –ù–µ—Ç\n")
            
            # –í—ã—Å–æ–∫–∞—è –¥–æ–ª—è –Ω—É–ª–µ–π
            if quality_flags.get('has_high_zero_columns', False):
                f.write(f"- ‚ö†Ô∏è **–í—ã—Å–æ–∫–∞—è –¥–æ–ª—è –Ω—É–ª–µ–π (> {zero_threshold}%):** –î–ê\n")
                if quality_flags.get('high_zero_columns'):
                    for col_info in quality_flags['high_zero_columns'][:3]:
                        f.write(f"  - `{col_info['column']}`: {col_info['zero_count']} –Ω—É–ª–µ–π ({col_info['zero_percentage']}%)\n")
            else:
                f.write(f"- ‚úÖ **–í—ã—Å–æ–∫–∞—è –¥–æ–ª—è –Ω—É–ª–µ–π:** –ù–µ—Ç\n")
            
            f.write("\n")
        
        # ==================== –ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø ====================
        f.write("## üï≥Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n\n")
        
        if missing_df.empty:
            f.write("‚úÖ **–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç.**\n\n")
        else:
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_missing = missing_df['missing_count'].sum()
            total_cells = summary.n_rows * summary.n_cols
            overall_missing_percent = (total_missing / total_cells) * 100
            
            f.write(f"### –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
            f.write(f"- –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤: `{total_missing}`\n")
            f.write(f"- –î–æ–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: `{overall_missing_percent:.2f}%`\n")
            f.write(f"- –°—Ç–æ–ª–±—Ü–æ–≤ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: `{len(missing_df[missing_df['missing_count'] > 0])}`\n\n")
            
            # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (—Å —É—á—ë—Ç–æ–º min_missing_for_detail)
            problem_cols = missing_df[missing_df['missing_share'] * 100 >= min_missing_for_detail]
            
            if not problem_cols.empty:
                f.write(f"### ‚ö†Ô∏è –°—Ç–æ–ª–±—Ü—ã —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ > {min_missing_for_detail}%\n\n")
                f.write("| –°—Ç–æ–ª–±–µ—Ü | –ü—Ä–æ–ø—É—Å–∫–æ–≤ | –î–æ–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ |\n")
                f.write("|---------|-----------|----------------|\n")
                
                for idx, row in problem_cols.iterrows():
                    f.write(f"| `{idx}` | {row['missing_count']} | {row['missing_share']:.2%} |\n")
                
                f.write("\n")
            
            f.write("> –ü–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —Ñ–∞–π–ª–µ `missing.csv`\n\n")
        
        # ==================== –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò ====================
        f.write("## üìä –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n\n")
        
        if not top_cats:
            f.write("–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n\n")
        else:
            f.write(f"–ù–∞–π–¥–µ–Ω–æ `{len(top_cats)}` –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n")
            f.write(f"–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ø-`{top_k_categories}` –∑–Ω–∞—á–µ–Ω–∏–π.\n\n")
            
            # –ü—Ä–∏–º–µ—Ä –¥–ª—è –ø–µ—Ä–≤—ã—Ö 3 —Å—Ç–æ–ª–±—Ü–æ–≤
            for i, (col_name, categories) in enumerate(top_cats.items()):
                if i >= 3:  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3
                    remaining = len(top_cats) - 3
                    f.write(f"\n... –∏ –µ—â—ë `{remaining}` –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n")
                    break
                
                f.write(f"### `{col_name}`\n")
                f.write(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: `{categories['n_unique']}`\n\n")
                
                if categories['top_values']:
                    f.write("| –ó–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ | –î–æ–ª—è |\n")
                    f.write("|----------|------------|------|\n")
                    
                    for value, count in categories['top_values'].items():
                        percentage = (count / summary.n_rows) * 100
                        f.write(f"| `{value}` | {count} | {percentage:.1f}% |\n")
                
                f.write("\n")
            
            f.write("> –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –≤ –ø–∞–ø–∫–µ `top_categories/`\n\n")
        
        # ==================== –ö–û–†–†–ï–õ–Ø–¶–ò–ò ====================
        if include_correlation:
            f.write("## üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞\n\n")
            
            if corr_df.empty or len(corr_df) <= 1:
                f.write("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.\n\n")
            else:
                f.write(f"–†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã: `{corr_df.shape[0]}√ó{corr_df.shape[1]}`\n\n")
                
                # –°–∞–º—ã–µ —Å–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                strong_correlations = []
                for i in range(len(corr_df.columns)):
                    for j in range(i+1, len(corr_df.columns)):
                        corr_value = corr_df.iloc[i, j]
                        if abs(corr_value) > 0.7:  # —Å–∏–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
                            strong_correlations.append((
                                corr_df.columns[i],
                                corr_df.columns[j],
                                corr_value
                            ))
                
                if strong_correlations:
                    f.write("### –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (|r| > 0.7)\n\n")
                    f.write("| –ü—Ä–∏–∑–Ω–∞–∫ 1 | –ü—Ä–∏–∑–Ω–∞–∫ 2 | –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç |\n")
                    f.write("|-----------|-----------|-------------|\n")
                    
                    for col1, col2, corr_val in strong_correlations[:10]:  # –ø–µ—Ä–≤—ã–µ 10
                        f.write(f"| `{col1}` | `{col2}` | {corr_val:.3f} |\n")
                    
                    if len(strong_correlations) > 10:
                        f.write(f"| ... | ... | ... |\n")
                    
                    f.write("\n")
                
                f.write("> –ü–æ–ª–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –≤ —Ñ–∞–π–ª–µ `correlation.csv`\n\n")
        
        # ==================== –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò ====================
        f.write("## üé® –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n\n")
        
        f.write("### –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n")
        f.write(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º: –¥–æ `{max_hist_columns}` —à—Ç.\n")
        f.write("–§–∞–π–ª—ã: `hist_*.png`\n\n")
        
        f.write("### –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n")
        f.write("–§–∞–π–ª: `missing_matrix.png`\n\n")
        
        if include_correlation and not corr_df.empty:
            f.write("### –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π\n")
            f.write("–§–∞–π–ª: `correlation_heatmap.png`\n\n")
        
        # ==================== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ====================
        f.write("## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
        
        recommendations = []
        
        if quality_flags.get('too_many_missing', False):
            recommendations.append("**–ü—Ä–æ–ø—É—Å–∫–∏:** –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏–º–ø—É—Ç–∞—Ü–∏—é –∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –¥–æ–ª–µ–π –ø—Ä–æ–ø—É—Å–∫–æ–≤.")
        
        if quality_flags.get('too_few_rows', False):
            recommendations.append("**–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö:** –î–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö.")
        
        if advanced_quality_check:
            if quality_flags.get('has_constant_columns', False):
                recommendations.append("**–ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:** –£–¥–∞–ª–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã —Å–æ –≤—Å–µ–º–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.")
            
            if quality_flags.get('has_outliers', False):
                recommendations.append("**–í—ã–±—Ä–æ—Å—ã:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—ã–±—Ä–æ—Å—ã –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –æ—à–∏–±–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö.")
            
            if quality_flags.get('has_id_duplicates', False):
                recommendations.append("**–î—É–±–ª–∏–∫–∞—Ç—ã ID:** –ò—Å—Å–ª–µ–¥—É–π—Ç–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤.")
        
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                f.write(f"{i}. {rec}\n")
        else:
            f.write("‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –≤ —Ü–µ–ª–æ–º —Ö–æ—Ä–æ—à–µ–µ. –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –∞–Ω–∞–ª–∏–∑!\n")
        
        f.write("\n")
        
        # ==================== –§–ê–ô–õ–´ –û–¢–ß–Å–¢–ê ====================
        f.write("## üìÅ –§–∞–π–ª—ã –æ—Ç—á—ë—Ç–∞\n\n")
        f.write("| –§–∞–π–ª | –û–ø–∏—Å–∞–Ω–∏–µ |\n")
        f.write("|------|----------|\n")
        f.write(f"| `{md_path.name}` | –≠—Ç–æ—Ç –æ—Ç—á—ë—Ç (Markdown) |\n")
        f.write(f"| `summary.csv` | –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º |\n")
        
        if not missing_df.empty:
            f.write(f"| `missing.csv` | –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º |\n")
            f.write(f"| `missing_matrix.png` | –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ |\n")
        
        if include_correlation and not corr_df.empty:
            f.write(f"| `correlation.csv` | –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π |\n")
            f.write(f"| `correlation_heatmap.png` | –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π |\n")
        
        if top_cats:
            f.write(f"| `top_categories/*.csv` | –¢–æ–ø-–∑–Ω–∞—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n")
        
        if advanced_quality_check:
            f.write(f"| `quality_flags.json` | –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏ –∫–∞—á–µ—Å—Ç–≤–∞ |\n")
        
        f.write(f"| `hist_*.png` | –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n")
        
        f.write("\n")
        f.write("---\n")
        f.write("*–û—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å –ø–æ–º–æ—â—å—é `eda-cli`*\n")
        f.write(f"*–í–µ—Ä—Å–∏—è: 1.1.0 | –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {'–î–∞' if advanced_quality_check else '–ù–µ—Ç'}*\n")
    
    # 8. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
    typer.echo("‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
    
    # 8.1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
    plot_histograms_per_column(df, figures_dir, max_columns=max_hist_columns)
    
    # 8.2. –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    plot_missing_matrix(df, figures_dir / "missing_matrix.png")
    
    # 8.3. –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    if include_correlation and not corr_df.empty:
        plot_correlation_heatmap(df, figures_dir / "correlation_heatmap.png")
    
    # 9. –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    execution_time = time.time() - start_time
    
    typer.echo("\n" + "=" * 60)
    typer.echo("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!")
    typer.echo("=" * 60)
    typer.echo(f"üìä –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    typer.echo(f"   ‚Ä¢ –û—Ç—á—ë—Ç: {md_path}")
    typer.echo(f"   ‚Ä¢ –°—Ç–æ–ª–±—Ü–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {summary.n_cols}")
    typer.echo(f"   ‚Ä¢ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {quality_flags.get('quality_score', 0):.2f}/1.0")
    
    if advanced_quality_check:
        typer.echo(f"   ‚Ä¢ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏: quality_flags.json")
    
    typer.echo(f"\n‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
    typer.echo(f"üìÅ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {out_root}")
    typer.echo("=" * 60)

if __name__ == "__main__":
    app()
